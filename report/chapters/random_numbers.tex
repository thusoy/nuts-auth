\chapter{Random numbers}
\label{chp:random-numbers}

High quality random numbers are essential to the security of NAP. Using the Raspberry Pi for our satellite simulator is interesting in this regard, as it includes an on-board \gls{hwrng} as provided by the Broadcom 2835 \gls{soc}. This can be compared to modern Intel CPUs providing the RDRAND\footnote{Present on CPUs from the Ivy Bridge family and onwards} instruction. Utilizing these sources for randomness should be safer than relying on a \gls{prng}, since if the state of a \gls{prng} is leaked, previous and/or future numbers generated might be predicted. With a properly implemented \gls{hwrng}, this is not possible.

However, popular adoption of the RDRAND instruction has not happened. The Linux kernel provides it's own means of sampling entropy from the environment, mixing several pseudo-random sources into an entropy pool, as provided through the \texttt{/dev/urandom} and \texttt{/dev/random} interfaces. There's been discussion in the community about this\footnote{See f. ex Bruce Schneier's blog post about it at \url{https://www.schneier.com/blog/archives/2013/10/insecurities_in.html}, and Theodore Ts'o's post at \url{https://plus.google.com/+TheodoreTso/posts/SDcoemc9V3J}}, and largely it boils down to not wanting to rely on a single source of randomness. This follows the general pattern of avoiding a \gls{spof}, which is also very much in the interest of the NUTS project. Another point to be made is that Intel has declined to share the design specifications of their \gls{hwrng}, thus denying the community the possibility to verify that the design is solid and backdoor-free. In the wake of the NSA revelations and especially the BULLRUN program\footnote{Wikipedia has a good primer: http://en.wikipedia.org/wiki/Bullrun\_\%28decryption\_program\%29}, trust in American companies claiming to provide secure solutions is failing. The same thing applies to Broadcom, which supplies the \gls{hwrng} for our Raspberry Pis.

For the NUTS project, random numbers is important, but trust in American companies is unnecessary, as the Atmel UC3-AX chip powering the satellite does not provide a \gls{hwrng}, open or otherwise. Thus the problem of generating high-quality random numbers is still an important question for the integrity of the communications channel. Luckily, the satellite has lots of hardware interfaces sampling the environment, which should provide several high-quality sources of entropy. Generating random numbers from a sensor is a matter of sampling the \gls{lsb}, before any filtering or processing has happened on the signal.

Several of the interfaces on the satellite should be excellent for this purpose, such as the two radio interfaces (background noise), the magnetometers (variations in earths magnetic field), battery voltages, CPU temperatures, camera noise, sun sensors and possibly more. A good RNG would rely on as many of these as possible.

None of these interfaces were made for being used as entropy sources though, and may be biased, in the sense that the bitstream generated by sampling the \gls{lsb} might contain more than 1s than 0s, or that some pattern might be spotted in the bitstream, such as clustering of 1s or similar. There exists several tests for testing the quality of a random bitstream, such as the NIST SP 800-90A and the FIPS 140-2 from official standards bodies, and less official tests such as the dieharder\footnote{The self-titled "Swiss army knife of random number test suites", \url{http://www.phy.duke.edu/~rgb/General/dieharder.php}} tests, which is a suite of different randomness tests. These are not adequate for testing predictability though, which is essential for any CSPRNG. Consider an RNG outputting digits of Pi. The RNG would pass all the randomness tests with flying colors, as there's no pattern or repeating element to the digits of Pi, but if an attacker observes the output, it's trivial for him to compute his own digits of Pi and search for the pattern outputted by the RNG. Once he's found where the RNG is, he can predict all future values outputted by the RNG.

It is however possible to use testing to detect catastrophic failure of the noise source, such as a stuck bit. This can be done i.e by using the Repetition Count Test or Adaptive Proportion Test from NIST SP800-90b (\cite{sp800-90b}), checking to see whether a value repeats itself too often, or whether a value appears more often than it statistically should be expected to.

However, even if the interfaces might be biased, they might still contain some actual entropy. One way to utilize them would be to guess at the entropy in the input using a pessimistic estimator, whiten the input to remove any bias, and mix it together with the other interfaces. Sum the different estimates of entropy from the inputs, and you'd have a good measure for the actual entropy of the final mixed stream of bytes. This is similar to how the Linux kernel initializes it's random pool, when a user requests random bytes, the pool content is hashed using SHA-1, and the entropy estimate is reduced with the number of bytes read. Part of the output is also mixed back into the pool.

However, our case differs from the Linux case, as the Linux kernel is written to be able to generate random numbers even in the absence of physical entropy sources, extracting entropy from other environmental sources such as timing between keystrokes, interrupts and network events. We can sample physical noise sources whenever we want, thus not having the same need for storing a pool of random data.

The problem with storing a pool of random data, is that if the pool is compromised, future output from the RNG can be predicted. This predictability compromises backwards security, the property that future output should not be predictable. This in contrast to forwards security, where previous outputs should be unguessable if one knows the current state of the RNG. Forwards security will not be compromised if the pool is leaked, as that would require successful cryptanalysis of the hash function used to generate the output from the pool, since it feeds output back into the pool.

We can thus separate two different designs here; a CSPRNG, that doesn't utilize a pool and thus have no internal state that can be compromised, and a PRNG, that utilizes a pool at the risk of its compromise. Some properties of the two approaches are shown in \autoref{tab:rng-design}.p

\begin{table}
\centering
    \begin{tabular}{| l | p{3cm} | p{3cm} |}
    \hline
    \textbf{Property} & \textbf{CSPRNG} & \textbf{PRNG} \\ \hline
    Mode of operation & Sample, whiten and mix noise sources on demand & Sample, whiten and mix noise sources on startup into a pool, hash pool contents on demand, mix part of output back into pool \\ \hline
    Speed & Depends on sampling speed and entropy of noise sources & Very fast \\ \hline
    Forwards/backwards security & Both & Only forwards, backwards only if pool is re-seeded \\ \hline
    Needs to store state & No & Yes \\ \hline
    \end{tabular}
    \caption{Different properties of a CSPRNG and a PRNG}\label{tab:rng-design}
\end{table}

For both cases, the noise sources can be treated in the same way. They need health tests, need to measure their outputted entropy, need a whitening function to remove bias, and there needs to be some way to mix the different outputs together. \cite{linux-prng-revisited} contains a good analysis of the mixing function and the estimator in Linux, and contains good points for consideration in the design of such components. RFC4086 (\cite{rfc4086}) also has a good introduction to the topic, and contains examples of both good and bad designs.

One would like to have a bit more data before choosing between the CSPRNG and the PRNG approaches, especially regarding the expected performance. However, since the performance of the CSPRNG will be a function of the estimated entropy of the sampled data, actual in-space measurements from the noise sources is necessary, as we can't tell from how they behave within Earth's atmosphere how they'll behave in space. We're not aware of any data from other in-space units sampling for randomness, and thus might have to perform these measurements ourselves.

Hence, we recommend a hybrid approach, whereas the RNG on the satellite is capable of performing both modes of operation. It could thus behave like a CSPRNG in the general case, but if performance falls below a given threshold, or noise sources fail the health tests, it might fall back to the pool-based approach, sacrificing backwards security until the noise sources return to healthy status and are able to re-seed the pool and be sampled directly. Development of such a module is recommended as future work.
